@inproceedings{radford2021learning,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Chris Hallacy and
                  Aditya Ramesh and
                  Gabriel Goh and
                  Sandhini Agarwal and
                  Girish Sastry and
                  Amanda Askell and
                  Pamela Mishkin and
                  Jack Clark and
                  Gretchen Krueger and
                  Ilya Sutskever},
  title        = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle    = {Proceedings of ICML},
  pages        = {8748--8763},
  year         = {2021},
}

@inproceedings{alayrac2022flamingo,
  author       = {Jean{-}Baptiste Alayrac and
                  Jeff Donahue and
                  Pauline Luc and
                  Antoine Miech and
                  Iain Barr and
                  Yana Hasson and
                  Karel Lenc and
                  Arthur Mensch and
                  Katherine Millican and
                  Malcolm Reynolds and
                  Roman Ring and
                  Eliza Rutherford and
                  Serkan Cabi and
                  Tengda Han and
                  Zhitao Gong and
                  Sina Samangooei and
                  Marianne Monteiro and
                  Jacob L. Menick and
                  Sebastian Borgeaud and
                  Andy Brock and
                  Aida Nematzadeh and
                  Sahand Sharifzadeh and
                  Mikolaj Binkowski and
                  Ricardo Barreira and
                  Oriol Vinyals and
                  Andrew Zisserman and
                  Kar{\'{e}}n Simonyan},
  title        = {Flamingo: a Visual Language Model for Few-Shot Learning},
  booktitle    = {Proceedings of NeurIPS},
  year         = {2022},
}

w3c valid html

@article{gpt4technicalreport,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={arXiv:2303.08774},
  year={2023}
}

@inproceedings{li2023blip2,
  author       = {Junnan Li and
                  Dongxu Li and
                  Silvio Savarese and
                  Steven C. H. Hoi},
  title        = {{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image
                  Encoders and Large Language Models},
  booktitle    = {Proceedings of ICML},
  volume       = {202},
  pages        = {19730--19742},
  year         = {2023},
}


@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv:2310.03744},
  year={2023}
}

@article{chen2023shikra,
  title={Shikra: Unleashing multimodal LLM's referential dialogue magic},
  author={Chen, Ke and Zhang, Zhe and Zeng, Wen and Zhang, Richang and Zhu, Feng and Zhao, Rui},
  journal={arXiv:2306.15195},
  year={2023}
}

@article{li2023videochat,
  title={VideoChat: Chat-centric video understanding},
  author={Li, Kunyu and He, Yi and Wang, Yinan and Li, Wei and Wang, Wen and Luo, Ping and Wang, Yu and Qiao, Yang},
  journal={arXiv:2305.06355},
  year={2023}
}

@article{hong2023llama,
  title={LLaMA-Adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Hong, Weihan and Wang, Wen and Tseng, Jui and Lewis, Mike and Shi, Xisen and Chang, Xu},
  journal={arXiv:2303.16199},
  year={2023}
}

@article{fu2023mme,
  title={MME: A comprehensive evaluation benchmark for multimodal large language models},
  author={Fu, Chaoyou and Chen, Peihao and Shen, Yubo and Qin, Yikai and Zhang, Mingrui and Lin, Xue},
  journal={arXiv:2306.13394},
  year={2023}
}

@article{yin2023woodpecker,
  author       = {Shukang Yin and
                  Chaoyou Fu and
                  Sirui Zhao and
                  Tong Xu and
                  Hao Wang and
                  Dianbo Sui and
                  Yunhang Shen and
                  Ke Li and
                  Xing Sun and
                  Enhong Chen},
  title        = {Woodpecker: hallucination correction for multimodal large language
                  models},
  journal      = {Sci. China Inf. Sci.},
  volume       = {67},
  number       = {12},
  year         = {2024},
}

@inproceedings{lu2023scienceqa,
  author       = {Pan Lu and
                  Swaroop Mishra and
                  Tanglin Xia and
                  Liang Qiu and
                  Kai{-}Wei Chang and
                  Song{-}Chun Zhu and
                  Oyvind Tafjord and
                  Peter Clark and
                  Ashwin Kalyan},
  title        = {Learn to Explain: Multimodal Reasoning via Thought Chains for Science
                  Question Answering},
  booktitle    = {Proceedings of NeurIPS},
  year         = {2022},
}

@article{bai2023qwen,
  title={Qwen-VL: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv:2308.12966},
  year={2023}
}

@inproceedings{wu2023nextgpt,
  author       = {Shengqiong Wu and
                  Hao Fei and
                  Leigang Qu and
                  Wei Ji and
                  Tat{-}Seng Chua},
  title        = {NExT-GPT: Any-to-Any Multimodal {LLM}},
  booktitle    = {Proceedings of ICML},
  year         = {2024},
}

@inproceedings{li2023llava,
  author       = {Chunyuan Li and
                  Cliff Wong and
                  Sheng Zhang and
                  Naoto Usuyama and
                  Haotian Liu and
                  Jianwei Yang and
                  Tristan Naumann and
                  Hoifung Poon and
                  Jianfeng Gao},
  title        = {LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine
                  in One Day},
  booktitle    = {Proceedings of NeurIPS},
  year         = {2023},
}

@article{yang2023mmreact,
  title={MM-REACT: Prompting ChatGPT for multimodal reasoning and action},
  author={Yang, Zhengyuan and Li, Lei and Wang, Jianfeng and Lin, Kevin and Azarnasab, Ehsan and Ahmed, Farhad and Liu, Zicheng and Liu, Cong and Zeng, Michael and Wang, Lijuan},
  journal={arXiv:2303.11381},
  year={2023}
}

@article{czll24corr,
    author = {Chaoyun Zhang and
                    Shilin He and
                    Jiaxu Qian and
                    Bowen Li and
                    Liqun Li and
                    Si Qin and
                    Yu Kang and
                    Minghua Ma and
                    Guyue Liu and
                    Qingwei Lin and
                    Saravan Rajmohan and
                    Dongmei Zhang and
                    Qi Zhang},
    title = {Large Language Model-Brained {GUI} Agents: {A} Survey},
    journal = {CoRR},
    volume = {abs/2411.18279},
    year = {2024}
}

@inproceedings{sywt22nips,
    author = {Shunyu Yao and
                    Howard Chen and
                    John Yang and
                    Karthik Narasimhan},
    title = {WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents},
    booktitle = {Proceedings of NeurIPS},
    year = {2022}
}


@inproceedings{lsmg22emnlp,
    author = {Liangtai Sun and
                    Xingyu Chen and
                    Lu Chen and
                    Tianle Dai and
                    Zichen Zhu and
                    Kai Yu},
    title = {{META-GUI:} Towards Multi-modal Conversational Agents on Mobile {GUI}},
    booktitle = {Proceedings of EMNLP},
    pages = {6699--6712},
    year = {2022}
}

@inproceedings{tswo17icml,
    author = {Tianlin Shi and
                    Andrej Karpathy and
                    Linxi Fan and
                    Jonathan Hernandez and
                    Percy Liang},
    title = {World of Bits: An Open-Domain Platform for Web-Based Agents},
    booktitle = {Proceedings of ICML},
    pages = {3135--3144},
    year = {2017}
}

@inproceedings{craa23nips,
    author = {Christopher Rawles and
                    Alice Li and
                    Daniel Rodriguez and
                    Oriana Riva and
                    Timothy P. Lillicrap},
    title = {AndroidInTheWild: {A} Large-Scale Dataset For Android Device Control},
    booktitle = {Proceedings of NeurIPS},
    year = {2023}
}

@inproceedings{xdmt23nips,
    author = {Xiang Deng and
                    Yu Gu and
                    Boyuan Zheng and
                    Shijie Chen and
                    Samual Stevens and
                    Boshi Wang and
                    Huan Sun and
                    Yu Su},
    title = {Mind2Web: Towards a Generalist Agent for the Web},
    booktitle = {Proceedings of NeurIPS},
    year = {2023}
}

@inproceedings{szwa24iclr,
    author = {Shuyan Zhou and
                    Frank F. Xu and
                    Hao Zhu and
                    Xuhui Zhou and
                    Robert Lo and
                    Abishek Sridhar and
                    Xianyi Cheng and
                    Tianyue Ou and
                    Yonatan Bisk and
                    Daniel Fried and
                    Uri Alon and
                    Graham Neubig},
    title = {WebArena: {A} Realistic Web Environment for Building Autonomous Agents},
    booktitle = {Proceedings of ICLR},
    year = {2024}
}

@inproceedings{jyve24acl,
    author = {Jing Yu Koh and
                    Robert Lo and
                    Lawrence Jang and
                    Vikram Duvvur and
                    Ming Chong Lim and
                    Po{-}Yu Huang and
                    Graham Neubig and
                    Shuyan Zhou and
                    Russ Salakhutdinov and
                    Daniel Fried},
    title = {VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks},
    booktitle = {Proceedings of ACL},
    pages = {881--905},
    year = {2024}
}

@inproceedings{txob24nips,
    author = {Tianbao Xie and
                    Danyang Zhang and
                    Jixuan Chen and
                    Xiaochuan Li and
                    Siheng Zhao and
                    Ruisheng Cao and
                    Toh Jing Hua and
                    Zhoujun Cheng and
                    Dongchan Shin and
                    Fangyu Lei and
                    Yitao Liu and
                    Yiheng Xu and
                    Shuyan Zhou and
                    Silvio Savarese and
                    Caiming Xiong and
                    Victor Zhong and
                    Tao Yu},
    title = {OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments},
    booktitle = {Proceedings of NeurIPS},
    year = {2024}
}
@inproceedings{jzai24emnlp,
    author = {Jiwen Zhang and
                    Jihao Wu and
                    Yihua Teng and
                    Minghui Liao and
                    Nuo Xu and
                    Xiao Xiao and
                    Zhongyu Wei and
                    Duyu Tang},
    title = {Android in the Zoo: Chain-of-Action-Thought for {GUI} Agents},
    booktitle = {Findings of EMNLP},
    pages = {12016--12031},
    year = {2024}
}

@inproceedings{tlaz23emnlp,
    author = {Tao Li and
                    Gang Li and
                    Zhiwei Deng and
                    Bryan Wang and
                    Yang Li},
    title = {A Zero-Shot Language Agent for Computer Control with Structured Reflection},
    booktitle = {Findings of EMNLP},
    pages = {11261--11274},
    year = {2023}
}

@inproceedings{lzst24iclr,
    author = {Longtao Zheng and
                    Rundong Wang and
                    Xinrun Wang and
                    Bo An},
    title = {Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control},
    booktitle = {Proceedings of ICLR},
    year = {2024}
}

@inproceedings{pcad22icml,
    author = {Peter Conway Humphreys and
                    David Raposo and
                    Tobias Pohlen and
                    Gregory Thornton and
                    Rachita Chhaparia and
                    Alistair Muldal and
                    Josh Abramson and
                    Petko Georgiev and
                    Adam Santoro and
                    Timothy P. Lillicrap},
    title = {A data-driven approach for learning to control computers},
    booktitle = {Proceedings of ICML},
    pages = {9466--9482},
    year = {2022}
}

@inproceedings{psfp23nips,
    author = {Peter Shaw and
                    Mandar Joshi and
                    James Cohan and
                    Jonathan Berant and
                    Panupong Pasupat and
                    Hexiang Hu and
                    Urvashi Khandelwal and
                    Kenton Lee and
                    Kristina Toutanova},
    title = {From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces},
    booktitle = {Proceedings of NeurIPS},
    year = {2023}
}

@inproceedings{whca24cvpr,
    author = {Wenyi Hong and
                    Weihan Wang and
                    Qingsong Lv and
                    Jiazheng Xu and
                    Wenmeng Yu and
                    Junhui Ji and
                    Yan Wang and
                    Zihan Wang and
                    Yuxiao Dong and
                    Ming Ding and
                    Jie Tang},
    title = {CogAgent: {A} Visual Language Model for {GUI} Agents},
    booktitle = {Proceedings of CVPR},
    pages = {14281--14290},
    year = {2024}
}

@inproceedings{zzyo24acl,
    author = {Zhuosheng Zhang and
                    Aston Zhang},
    title = {You Only Look at Screens: Multimodal Chain-of-Action Agents},
    booktitle = {Findings of ACL},
    pages = {3132--3149},
    year = {2024}
}

@inproceedings{jwco22nips,
    author = {Jason Wei and
                    Xuezhi Wang and
                    Dale Schuurmans and
                    Maarten Bosma and
                    Brian Ichter and
                    Fei Xia and
                    Ed H. Chi and
                    Quoc V. Le and
                    Denny Zhou},
    title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
    booktitle = {Proceedings of NeurIPS},
    year = {2022}
}

@inproceedings{kcsh24acl,
    author = {Kanzhi Cheng and
                    Qiushi Sun and
                    Yougang Chu and
                    Fangzhi Xu and
                    Yantao Li and
                    Jianbing Zhang and
                    Zhiyong Wu},
    title = {SeeClick: Harnessing {GUI} Grounding for Advanced Visual {GUI} Agents},
    booktitle = {Proceedings of ACL},
    pages = {9313--9332},
    year = {2024}
}

@inproceedings{hlaa24kdd,
    author = {Hanyu Lai and
                    Xiao Liu and
                    Iat Long Iong and
                    Shuntian Yao and
                    Yuxuan Chen and
                    Pengbo Shen and
                    Hao Yu and
                    Hanchen Zhang and
                    Xiaohan Zhang and
                    Yuxiao Dong and
                    Jie Tang},
    title = {AutoWebGLM: {A} Large Language Model-based Web Navigating Agent},
    booktitle = {Proceedings of KDD},
    pages = {5295--5306},
    year = {2024}
}

@article{taae24corr,
    author = {Tamer Abuelsaad and
                    Deepak Akkil and
                    Prasenjit Dey and
                    Ashish Jagmohan and
                    Aditya Vempaty and
                    Ravi Kokku},
    title = {Agent-E: From Autonomous Web Navigation to Foundational Design Principles in Agentic Systems},
    journal = {CoRR},
    volume = {abs/2407.13032},
    year = {2024}
}

@article{yxau24corr,
    author = {Yiheng Xu and
                    Zekun Wang and
                    Junli Wang and
                    Dunjie Lu and
                    Tianbao Xie and
                    Amrita Saha and
                    Doyen Sahoo and
                    Tao Yu and
                    Caiming Xiong},
    title = {Aguvis: Unified Pure Vision Agents for Autonomous {GUI} Interaction},
    journal = {CoRR},
    volume = {abs/2412.04454},
    year = {2024}
}

@article{gpaa25corr,
    author = {Georgios Papoudakis and
                    Thomas Coste and
                    Zhihao Wu and
                    Jianye Hao and
                    Jun Wang and
                    Kun Shao},
    title = {AppVLM: {A} Lightweight Vision Language Model for Online App Control},
    journal = {CoRR},
    volume = {abs/2502.06395},
    year = {2025}
}

@article{hsfu24corr,
    author = {Huawen Shen and
                    Chang Liu and
                    Gengluo Li and
                    Xinlong Wang and
                    Yu Zhou and
                    Can Ma and
                    Xiangyang Ji},
    title = {Falcon-UI: Understanding {GUI} Before Following User Instructions},
    journal = {CoRR},
    volume = {abs/2412.09362},
    year = {2024}
}

@article{hlpa25corr,
    author = {Haowei Liu and
                    Xi Zhang and
                    Haiyang Xu and
                    Yuyang Wanyan and
                    Junyang Wang and
                    Ming Yan and
                    Ji Zhang and
                    Chunfeng Yuan and
                    Changsheng Xu and
                    Weiming Hu and
                    Fei Huang},
    title = {PC-Agent: {A} Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on {PC}},
    journal = {CoRR},
    volume = {abs/2502.14282},
    year = {2025}
}

@article{qsog24corr,
    author = {Qiushi Sun and
                    Kanzhi Cheng and
                    Zichen Ding and
                    Chuanyang Jin and
                    Yian Wang and
                    Fangzhi Xu and
                    Zhenyu Wu and
                    Chengyou Jia and
                    Liheng Chen and
                    Zhoumianze Liu and
                    Ben Kao and
                    Guohao Li and
                    Junxian He and
                    Yu Qiao and
                    Zhiyong Wu},
    title = {OS-Genesis: Automating {GUI} Agent Trajectory Construction via Reverse Task Synthesis},
    journal = {CoRR},
    volume = {abs/2412.19723},
    year = {2024}
}

@inproceedings{arlt21icml,
    author = {Alec Radford and
                    Jong Wook Kim and
                    Chris Hallacy and
                    Aditya Ramesh and
                    Gabriel Goh and
                    Sandhini Agarwal and
                    Girish Sastry and
                    Amanda Askell and
                    Pamela Mishkin and
                    Jack Clark and
                    Gretchen Krueger and
                    Ilya Sutskever},
    title = {Learning Transferable Visual Models From Natural Language Supervision},
    booktitle = {Proceedings of ICML},
    pages = {8748--8763},
    year = {2021}
}

@inproceedings{jlbb22icml,
    author = {Junnan Li and
                    Dongxu Li and
                    Caiming Xiong and
                    Steven C. H. Hoi},
    title = {{BLIP:} Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
    booktitle = {Proceedings of ICML},
    pages = {12888--12900},
    year = {2022}
}

@inproceedings{hlvi23nips,
    author = {Haotian Liu and
                    Chunyuan Li and
                    Qingyang Wu and
                    Yong Jae Lee},
    title = {Visual Instruction Tuning},
    booktitle = {Proceedings of NeurIPS},
    year = {2023}
}

@article{pwqv24corr,
    author = {Peng Wang and
                    Shuai Bai and
                    Sinan Tan and
                    Shijie Wang and
                    Zhihao Fan and
                    Jinze Bai and
                    Keqin Chen and
                    Xuejing Liu and
                    Jialin Wang and
                    Wenbin Ge and
                    Yang Fan and
                    Kai Dang and
                    Mengfei Du and
                    Xuancheng Ren and
                    Rui Men and
                    Dayiheng Liu and
                    Chang Zhou and
                    Jingren Zhou and
                    Junyang Lin},
    title = {Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
    journal = {CoRR},
    volume = {abs/2409.12191},
    year = {2024}
}

@article{openai2024gpt4ocard,
      title={GPT-4o System Card}, 
      author={OpenAI},
      journal = {arXiv:2410.21276},
      year = {2024}
}

@article{gemini,
  title        = {Gemini 2.5: Our Most Intelligent AI Model},
  author       = {Google DeepMind},
  year         = {2025},
}

@article{qwenvlmax,
    author = {Qwen Team},
    title = {Introducing Qwen-VL},
    year = 2024,
}

@article{claude3sonnet,
  author  = {Anthropic},
  title   = {Claude 3.7 Sonnet System Card},
  year    = {2025},
}

@inproceedings{schuhmann2022laion,
  author       = {Christoph Schuhmann and
                  Romain Beaumont and
                  Richard Vencu and
                  Cade Gordon and
                  Ross Wightman and
                  Mehdi Cherti and
                  Theo Coombes and
                  Aarush Katta and
                  Clayton Mullis and
                  Mitchell Wortsman and
                  Patrick Schramowski and
                  Srivatsa Kundurthy and
                  Katherine Crowson and
                  Ludwig Schmidt and
                  Robert Kaczmarczyk and
                  Jenia Jitsev},
  title        = {{LAION-5B:} An open large-scale dataset for training next generation
                  image-text models},
  booktitle    = {Proceedings of NeurIPS},
  year         = {2022},
}

@article{grok32024,
  title={Grok-3},
  author={xAITeam},
  year={2024}
}

@article{doubao,
  title={Doubao-vision-pro-32K},
  author={ByteDance Seed},
  year={2024}
}

@inproceedings{papineni-etal-2002-bleu,
  author       = {Kishore Papineni and
                  Salim Roukos and
                  Todd Ward and
                  Wei{-}Jing Zhu},
  title        = {Bleu: a Method for Automatic Evaluation of Machine Translation},
  booktitle    = {Proceedings of ACL},
  pages        = {311--318},
  year         = {2002},
}

@inproceedings{zhao24nips,
  author       = {Weichao Zhao and
                  Hao Feng and
                  Qi Liu and
                  Jingqun Tang and
                  Binghong Wu and
                  Lei Liao and
                  Shu Wei and
                  Yongjie Ye and
                  Hao Liu and
                  Wengang Zhou and
                  Houqiang Li and
                  Can Huang},
  title        = {TabPedia: Towards Comprehensive Visual Table Understanding with Concept
                  Synergy},
  booktitle    = {Proceedings of NeurIPS},
  year         = {2024},
}

@inproceedings{jin25aaai,
  author       = {Rihui Jin and
                  Yu Li and
                  Guilin Qi and
                  Nan Hu and
                  Yuan{-}Fang Li and
                  Jiaoyan Chen and
                  Jianan Wang and
                  Yongrui Chen and
                  Dehai Min and
                  Sheng Bi},
  title        = {HeGTa: Leveraging Heterogeneous Graph-enhanced Large Language Models
                  for Few-shot Complex Table Understanding},
  booktitle    = {Proceedings of AAAI},
  pages        = {24294--24302},
  year         = {2025},
}

@inproceedings{li25www,
  author       = {Jia{-}Nan Li and
                  Jian Guan and
                  Wei Wu and
                  Zhengtao Yu and
                  Rui Yan},
  title        = {2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding
                  for Large Language Models},
  booktitle    = {Proceedings of the {ACM} on Web Conference},
  pages        = {2450--2463},
  year         = {2025},
}
@inproceedings{zheng24acl,
  author       = {Mingyu Zheng and
                  Xinwei Feng and
                  Qingyi Si and
                  Qiaoqiao She and
                  Zheng Lin and
                  Wenbin Jiang and
                  Weiping Wang},
  title        = {Multimodal Table Understanding},
  booktitle    = {Proceedings of ACL},
  pages        = {9102--9124},
  year         = {2024},
}

@misc{pyautogui,
  author       = {Al Sweigart},
  title        = {PyAutoGUI: Cross-platform GUI automation for human beings},
  year         = {2023},
  howpublished = {\url{https://pyautogui.readthedocs.io/en/latest/}},
}

@inproceedings{DBLP:conf/eccv/KapoorBRKKAS24,
  author       = {Raghav Kapoor and
                  Yash Parag Butala and
                  Melisa Russak and
                  Jing Yu Koh and
                  Kiran Kamble and
                  Waseem AlShikh and
                  Ruslan Salakhutdinov},
  title        = {OmniACT: {A} Dataset and Benchmark for Enabling Multimodal Generalist
                  Autonomous Agents for Desktop and Web},
  booktitle    = {Proceedings of ECCV},
  pages        = {161--178},
  year         = {2024}
}

@article{DBLP:journals/corr/abs-2412-18426,
  author       = {Kangjia Zhao and
                  Jiahui Song and
                  Leigang Sha and
                  Haozhan Shen and
                  Zhi Chen and
                  Tiancheng Zhao and
                  Xiubo Liang and
                  Jianwei Yin},
  title        = {{GUI} Testing Arena: {A} Unified Benchmark for Advancing Autonomous
                  {GUI} Testing Agent},
  journal={arXiv:2412.18426},
  year         = {2024}
}



@article{pan2024webcanvasbenchmarkingwebagents,
      title={WebCanvas: Benchmarking Web Agents in Online Environments}, 
      author={Yichen Pan and Dehan Kong and Sida Zhou and Cheng Cui and Yifei Leng and Bing Jiang and Hangyu Liu and Yanyi Shang and Shuyan Zhou and Tongshuang Wu and Zhengyang Wu},
      year={2024},
      journal = {arXiv:2406.12373},
}



@article{DBLP:journals/corr/abs-2501-01149,
  author       = {Yuxiang Chai and
                  Hanhao Li and
                  Jiayu Zhang and
                  Liang Liu and
                  Guozhi Wang and
                  Shuai Ren and
                  Siyuan Huang and
                  Hongsheng Li},
  title        = {{A3:} Android Agent Arena for Mobile {GUI} Agents},
  journal      = {arXiv:2501.01149},
  year         = {2025}
}

@inproceedings{DBLP:conf/iclr/ChenYXYCWYZLWZ025,
  author       = {Jingxuan Chen and
                  Derek Yuen and
                  Bin Xie and
                  Yuhao Yang and
                  Gongwei Chen and
                  Zhihao Wu and
                  Li Yixing and
                  Xurui Zhou and
                  Weiwen Liu and
                  Shuai Wang and
                  Kaiwen Zhou and
                  Rui Shao and
                  Liqiang Nie and
                  Yasheng Wang and
                  Jianye Hao and
                  Jun Wang and
                  Kun Shao},
  title        = {Spa-Bench: a comprehensive Benchmark for Smartphone Agent Evaluation},
  booktitle    = {Proceedings of ICLR},
  year         = {2025}
}
%这里没找到page

@inproceedings{DBLP:conf/iclr/ChenH0TZZHBGCLW25,
  author       = {Dongping Chen and
                  Yue Huang and
                  Siyuan Wu and
                  Jingyu Tang and
                  Huichi Zhou and
                  Qihui Zhang and
                  Zhigang He and
                  Yilin Bai and
                  Chujie Gao and
                  Liuyi Chen and
                  Yiqiang Li and
                  Chenlong Wang and
                  Yue Yu and
                  Tianshuo Zhou and
                  Zhen Li and
                  Yi Gui and
                  Yao Wan and
                  Pan Zhou and
                  Jianfeng Gao and
                  Lichao Sun},
  title        = {GUI-World: {A} Video Benchmark and Dataset for Multimodal GUI-oriented
                  Understanding},
  booktitle   = {Proceedings of ICLR},
  year         = {2025}
}

@article{bonatti2024windowsagentarenaevaluating,
      title={Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale}, 
      author={Rogerio Bonatti and Dan Zhao and Francesco Bonacci and Dillon Dupont and Sara Abdali and Yinheng Li and Yadong Lu and Justin Wagle and Kazuhito Koishida and Arthur Bucker and Lawrence Jang and Zack Hui},
      year={2024},
      journal={arXiv:2409.08264}
}

@inproceedings{DBLP:conf/nips/LinLGWYYWS24,
  author       = {Kevin Qinghong Lin and
                  Linjie Li and
                  Difei Gao and
                  Qinchen Wu and
                  Mingyi Yan and
                  Zhengyuan Yang and
                  Lijuan Wang and
                  Mike Zheng Shou},
  title        = {VideoGUI: {A} Benchmark for {GUI} Automation from Instructional Videos},
  booktitle     = {Proceedings of NeurIPS},
  year         = {2024}
}

@article{chai2025amexandroidmultiannotationexpo,
      title={AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents}, 
      author={Yuxiang Chai and Siyuan Huang and Yazhe Niu and Han Xiao and Liang Liu and Dingyu Zhang and Shuai Ren and Hongsheng Li},
      year={2025},
      journal={arXiv:2407.17490},
}

